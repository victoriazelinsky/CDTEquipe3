{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e893f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    "    BertTokenizer, \n",
    "    BertForSequenceClassification\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import evaluate\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "tqdm.pandas() # Utile pour avoir les bars de chargement avec pandas\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Config\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Paramètres de fine-tuning\n",
    "MODEL_NAME = \"ProsusAI/finbert\"\n",
    "DATA_PATH = \"./Data/sentiment_annotated_with_texts.csv\"  # <- mets ton fichier ici\n",
    "OUTPUT_DIR = \"./finbert_forex_finetuned\"\n",
    "MAX_LENGTH = 512\n",
    "NUM_EPOCHS = 3\n",
    "BATCH_SIZE_TRAIN = 16\n",
    "BATCH_SIZE_EVAL = 32\n",
    "LEARNING_RATE = 2e-5\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "print(f\"Torch device: {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "101aa4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>published_at</th>\n",
       "      <th>ticker</th>\n",
       "      <th>true_sentiment</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>url</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>finbert_sentiment</th>\n",
       "      <th>finbert_sent_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-12 07:47:00</td>\n",
       "      <td>EURCHF</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Euro to benefit from the ECBs pronounced hawki...</td>\n",
       "      <td>FXStreet Insights Team</td>\n",
       "      <td>https://www.fxstreet.com/news/euro-to-benefit-...</td>\n",
       "      <td>FX Street</td>\n",
       "      <td>The Euro was able to appreciate particularly s...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-12 10:34:00</td>\n",
       "      <td>EURCHF</td>\n",
       "      <td>Positive</td>\n",
       "      <td>EURCHF Trend higher may remain in place – ING</td>\n",
       "      <td>FXStreet Insights Team</td>\n",
       "      <td>https://www.fxstreet.com/news/eur-chf-trend-hi...</td>\n",
       "      <td>FX Street</td>\n",
       "      <td>EUR/CHF yesterday broke above 1.00. Economists...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-12 11:40:00</td>\n",
       "      <td>EURCHF</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Does a jump in EURCHF point to a break above 1...</td>\n",
       "      <td>FXStreet Insights Team</td>\n",
       "      <td>https://www.fxstreet.com/news/does-a-jump-in-e...</td>\n",
       "      <td>FX Street</td>\n",
       "      <td>EUR/CHF vaults parity for the first time since...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-12 15:32:00</td>\n",
       "      <td>EURCHF</td>\n",
       "      <td>Positive</td>\n",
       "      <td>EURCHF could extend its advance back to levels...</td>\n",
       "      <td>FXStreet Insights Team</td>\n",
       "      <td>https://www.fxstreet.com/news/eur-chf-could-ex...</td>\n",
       "      <td>FX Street</td>\n",
       "      <td>EUR/CHF climbs back above parity. Economists a...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-13 11:37:00</td>\n",
       "      <td>EURCHF</td>\n",
       "      <td>Positive</td>\n",
       "      <td>EURCHF to head higher towards 10130 and projec...</td>\n",
       "      <td>FXStreet Insights Team</td>\n",
       "      <td>https://www.fxstreet.com/news/eur-chf-to-head-...</td>\n",
       "      <td>FX Street</td>\n",
       "      <td>EUR/CHF has broken out above the sideways rang...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          published_at  ticker true_sentiment  \\\n",
       "0  2023-01-12 07:47:00  EURCHF       Positive   \n",
       "1  2023-01-12 10:34:00  EURCHF       Positive   \n",
       "2  2023-01-12 11:40:00  EURCHF        Neutral   \n",
       "3  2023-01-12 15:32:00  EURCHF       Positive   \n",
       "4  2023-01-13 11:37:00  EURCHF       Positive   \n",
       "\n",
       "                                               title                  author  \\\n",
       "0  Euro to benefit from the ECBs pronounced hawki...  FXStreet Insights Team   \n",
       "1      EURCHF Trend higher may remain in place – ING  FXStreet Insights Team   \n",
       "2  Does a jump in EURCHF point to a break above 1...  FXStreet Insights Team   \n",
       "3  EURCHF could extend its advance back to levels...  FXStreet Insights Team   \n",
       "4  EURCHF to head higher towards 10130 and projec...  FXStreet Insights Team   \n",
       "\n",
       "                                                 url     source  \\\n",
       "0  https://www.fxstreet.com/news/euro-to-benefit-...  FX Street   \n",
       "1  https://www.fxstreet.com/news/eur-chf-trend-hi...  FX Street   \n",
       "2  https://www.fxstreet.com/news/does-a-jump-in-e...  FX Street   \n",
       "3  https://www.fxstreet.com/news/eur-chf-could-ex...  FX Street   \n",
       "4  https://www.fxstreet.com/news/eur-chf-to-head-...  FX Street   \n",
       "\n",
       "                                                text finbert_sentiment  \\\n",
       "0  The Euro was able to appreciate particularly s...          Positive   \n",
       "1  EUR/CHF yesterday broke above 1.00. Economists...          Positive   \n",
       "2  EUR/CHF vaults parity for the first time since...           Neutral   \n",
       "3  EUR/CHF climbs back above parity. Economists a...          Positive   \n",
       "4  EUR/CHF has broken out above the sideways rang...          Positive   \n",
       "\n",
       "   finbert_sent_score  \n",
       "0                0.85  \n",
       "1                0.51  \n",
       "2                0.37  \n",
       "3                0.64  \n",
       "4                0.83  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "df['title'] = df['title'].astype(str).str.strip()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c301f2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping labels (index -> label): {0: 'Negative', 1: 'Neutral', 2: 'Positive'}\n",
      "Nombre de classes : 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label_str</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Euro to benefit from the ECBs pronounced hawki...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EURCHF Trend higher may remain in place – ING</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Does a jump in EURCHF point to a break above 1...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EURCHF could extend its advance back to levels...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EURCHF to head higher towards 10130 and projec...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EURCHF Room for the Euro to extend the move hi...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title label_str  label\n",
       "0  Euro to benefit from the ECBs pronounced hawki...  Positive      2\n",
       "1      EURCHF Trend higher may remain in place – ING  Positive      2\n",
       "2  Does a jump in EURCHF point to a break above 1...   Neutral      1\n",
       "3  EURCHF could extend its advance back to levels...  Positive      2\n",
       "4  EURCHF to head higher towards 10130 and projec...  Positive      2\n",
       "5  EURCHF Room for the Euro to extend the move hi...  Positive      2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "df['label_str'] = df['true_sentiment'].astype(str)\n",
    "df['label'] = le.fit_transform(df['label_str'])\n",
    "label_map = {int(i): c for i, c in enumerate(le.classes_)}\n",
    "num_labels = len(le.classes_)\n",
    "\n",
    "print(\"Mapping labels (index -> label):\", label_map)\n",
    "print(\"Nombre de classes :\", num_labels)\n",
    "df[['title','label_str','label']].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09a56b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time split utilisé. Train 1832, Val 229, Test 230\n"
     ]
    }
   ],
   "source": [
    "# Split train/val/test\n",
    "# Si published_at est présent et parseable, on fait une séparation temporelle (80/10/10).\n",
    "use_time_split = False\n",
    "if 'published_at' in df.columns:\n",
    "    # essaie de parser la date\n",
    "    try:\n",
    "        df['published_at_parsed'] = pd.to_datetime(df['published_at'], utc=True, errors='coerce')\n",
    "        n_na_dates = df['published_at_parsed'].isna().sum()\n",
    "        if n_na_dates == 0:\n",
    "            use_time_split = True\n",
    "        else:\n",
    "            print(f\"[WARN] {n_na_dates} lignes ont des dates non parsables ; on utilisera un split aléatoire stratifié.\")\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] Erreur parsing dates :\", e)\n",
    "\n",
    "if use_time_split:\n",
    "    # tri par date, découpage temporel\n",
    "    df = df.sort_values('published_at_parsed').reset_index(drop=True)\n",
    "    n = len(df)\n",
    "    i_train = int(n * 0.80)\n",
    "    i_val = int(n * 0.90)\n",
    "    train_df = df.iloc[:i_train].reset_index(drop=True)\n",
    "    val_df   = df.iloc[i_train:i_val].reset_index(drop=True)\n",
    "    test_df  = df.iloc[i_val:].reset_index(drop=True)\n",
    "    print(f\"Time split utilisé. Train {len(train_df)}, Val {len(val_df)}, Test {len(test_df)}\")\n",
    "else:\n",
    "    # split stratifié aléatoire (80/10/10)\n",
    "    train_temp, test_df = train_test_split(df, test_size=0.10, random_state=SEED, stratify=df['label'])\n",
    "    train_df, val_df = train_test_split(train_temp, test_size=0.1111, random_state=SEED, stratify=train_temp['label'])  # ~80/10/10\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    val_df = val_df.reset_index(drop=True)\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "    print(f\"Random stratified split utilisé. Train {len(train_df)}, Val {len(val_df)}, Test {len(test_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa5fd4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemples (train) :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': 'Euro to benefit from the ECBs pronounced hawkish determination – Commerzbank',\n",
       " 'label': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertir en datasets Hugging Face et renommer colonnes utiles\n",
    "hf_train = Dataset.from_pandas(train_df[['title','label']].rename(columns={'title':'text'}))\n",
    "hf_val   = Dataset.from_pandas(val_df[['title','label']].rename(columns={'title':'text'}))\n",
    "hf_test  = Dataset.from_pandas(test_df[['title','label']].rename(columns={'title':'text'}))\n",
    "\n",
    "print(\"Exemples (train) :\")\n",
    "hf_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ae5d58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a872aa20dce049699afc46408f6928c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1832 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6991dd62e1e14035a201a4dfac55d7ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/229 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7af5d1aa39e249e395861f3807e91b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/230 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenizer + préparation des inputs\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_labels)\n",
    "\n",
    "def preprocess_fn(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=MAX_LENGTH)\n",
    "\n",
    "hf_train = hf_train.map(preprocess_fn, batched=True, remove_columns=['text'])\n",
    "hf_val   = hf_val.map(preprocess_fn, batched=True, remove_columns=['text'])\n",
    "hf_test  = hf_test.map(preprocess_fn, batched=True, remove_columns=['text'])\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb55f99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métriques\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "        \"f1_macro\": f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"],\n",
    "        \"precision_macro\": precision.compute(predictions=preds, references=labels, average=\"macro\")[\"precision\"],\n",
    "        \"recall_macro\": recall.compute(predictions=preds, references=labels, average=\"macro\")[\"recall\"],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64111fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leisk\\AppData\\Local\\Temp\\ipykernel_21708\\491149278.py:19: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='345' max='345' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [345/345 04:23, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.783408</td>\n",
       "      <td>0.650655</td>\n",
       "      <td>0.611952</td>\n",
       "      <td>0.717914</td>\n",
       "      <td>0.601635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.628378</td>\n",
       "      <td>0.737991</td>\n",
       "      <td>0.741858</td>\n",
       "      <td>0.749137</td>\n",
       "      <td>0.758562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.593195</td>\n",
       "      <td>0.781659</td>\n",
       "      <td>0.782987</td>\n",
       "      <td>0.781865</td>\n",
       "      <td>0.788648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=345, training_loss=0.7527831146682518, metrics={'train_runtime': 264.7313, 'train_samples_per_second': 20.761, 'train_steps_per_second': 1.303, 'total_flos': 1446071343833088.0, 'train_loss': 0.7527831146682518, 'epoch': 3.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration du Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    per_device_train_batch_size=BATCH_SIZE_TRAIN,\n",
    "    per_device_eval_batch_size=BATCH_SIZE_EVAL,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    greater_is_better=True,\n",
    "    save_total_limit=2,\n",
    "    seed=SEED,\n",
    "    push_to_hub=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=hf_train,\n",
    "    eval_dataset=hf_val,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Entraînement\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc538251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Évaluation sur le jeu test :\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.7011784911155701, 'test_accuracy': 0.7565217391304347, 'test_f1_macro': 0.7470736006042781, 'test_precision_macro': 0.7518518518518519, 'test_recall_macro': 0.7509839176905405, 'test_runtime': 3.6255, 'test_samples_per_second': 63.44, 'test_steps_per_second': 2.207}\n"
     ]
    }
   ],
   "source": [
    "# Évaluation finale (test set)\n",
    "print(\"Évaluation sur le jeu test :\")\n",
    "metrics = trainer.predict(hf_test)\n",
    "print(metrics.metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfe77569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f43af512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle sauvegardé dans : ./finbert_forex_finetuned\n",
      "Mapping labels sauvegardé dans label_map.json\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarde modèle + tokenizer + mapping labels + sample preds\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "trainer.save_model(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIR, \"label_map.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(label_map, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Modèle sauvegardé dans :\", OUTPUT_DIR)\n",
    "print(\"Mapping labels sauvegardé dans label_map.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c6101b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2291/2291 [00:12<00:00, 176.40it/s]\n"
     ]
    }
   ],
   "source": [
    "ft_model = trainer.model.to(DEVICE)\n",
    "\n",
    "def ft_eval(row) :\n",
    "    text = row['title']\n",
    "    with torch.no_grad() :\n",
    "        prob = torch.softmax(ft_model(**tokenizer(text, return_tensors=\"pt\").to(DEVICE)).logits, dim=1).to('cpu')\n",
    "    sentiment_labels = ['Negative', 'Neutral', 'Positive']\n",
    "    predicted_sentiment_index = torch.argmax(prob, dim=1).item()\n",
    "    predicted_sentiment = sentiment_labels[predicted_sentiment_index]\n",
    "    return predicted_sentiment\n",
    "\n",
    "df[\"ft_pred\"] = df.progress_apply(ft_eval, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e5782b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8489742470536883)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df[\"ft_pred\"] == df[\"true_sentiment\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dce8f033",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2264/2264 [00:12<00:00, 178.86it/s]\n"
     ]
    }
   ],
   "source": [
    "df_eval = pd.read_csv(\"./Data/Chatgpt.csv\")\n",
    "df_eval['title'] = df_eval['paraphrased_title']\n",
    "df_eval[\"ft_pred\"] = df_eval.progress_apply(ft_eval, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff780b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     1677\n",
       "False     587\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_eval[\"ft_pred\"] == df_eval[\"true_sentiment\"]).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
